{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52af24e",
   "metadata": {},
   "source": [
    "### Set Path (Won't be needed once `setup.py` is finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022cd9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, sys.path[0][:-8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdeea0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f064887f",
   "metadata": {},
   "source": [
    "### Auglichem imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bcf959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auglichem.crystal import Compose, RandomRotationTransformation, SupercellTransformation\n",
    "from auglichem.crystal.data import CrystalDatasetWrapper\n",
    "from auglichem.crystal.models import CrystalGraphConvNet as CGCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125df85",
   "metadata": {},
   "source": [
    "### Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5d534c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CrystalDatasetWrapper in module auglichem.crystal.data._crystal_dataset:\n",
      "\n",
      "class CrystalDatasetWrapper(CrystalDataset)\n",
      " |  CrystalDatasetWrapper(*args, **kwds)\n",
      " |  \n",
      " |  The CIFData dataset is a wrapper for a dataset where the crystal structures\n",
      " |  are stored in the form of CIF files. The dataset should have the following\n",
      " |  directory structure:\n",
      " |  \n",
      " |  root_dir\n",
      " |  ├── id_prop.csv\n",
      " |  ├── atom_init.json\n",
      " |  ├── 0.cif\n",
      " |  ├── 1.cif\n",
      " |  ├── ...\n",
      " |  \n",
      " |  id_prop.csv: a CSV file with two columns. The first column recodes a\n",
      " |  unique ID for each crystal, and the second column recodes the value of\n",
      " |  target property.\n",
      " |  \n",
      " |  atom_init.json: a JSON file that stores the initialization vector for each\n",
      " |  element.\n",
      " |  \n",
      " |  ID.cif: a CIF file that recodes the crystal structure, where ID is the\n",
      " |  unique ID for the crystal.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |  root_dir: str\n",
      " |      The path to the root directory of the dataset\n",
      " |  max_num_nbr: int\n",
      " |      The maximum number of neighbors while constructing the crystal graph\n",
      " |  radius: float\n",
      " |      The cutoff radius for searching neighbors\n",
      " |  dmin: float\n",
      " |      The minimum distance for constructing GaussianDistance\n",
      " |  step: float\n",
      " |      The step size for constructing GaussianDistance\n",
      " |  random_seed: int\n",
      " |      Random seed for shuffling the dataset\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  \n",
      " |  atom_fea: torch.Tensor shape (n_i, atom_fea_len)\n",
      " |  nbr_fea: torch.Tensor shape (n_i, M, nbr_fea_len)\n",
      " |  nbr_fea_idx: torch.LongTensor shape (n_i, M)\n",
      " |  target: torch.Tensor shape (1, )\n",
      " |  cif_id: str or int\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CrystalDatasetWrapper\n",
      " |      CrystalDataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dataset, transform=None, split='random', batch_size=64, num_workers=0, valid_size=0.1, test_size=0.1, data_path=None, target=None, **kwargs)\n",
      " |      Wrapper Class to handle splitting dataset into train, validation, and test sets\n",
      " |      \n",
      " |      inputs:\n",
      " |      -------------------------\n",
      " |      dataset (str): One of our dataset: lanthanides, perovskites, band_gap, fermi_energy,\n",
      " |                                         or formation_energy\n",
      " |      transform (AbstractTransformation, optional): A crystal transformation\n",
      " |      split (str, default=random): Method of splitting data into train, validation, and\n",
      " |                                   test\n",
      " |      batch_size (int, default=64): Data batch size for train_loader\n",
      " |      num_workers (int, default=0): Number of worker processes for parallel data loading\n",
      " |      valid_size (float, optional, between [0, 1]): Fraction of data used for validation\n",
      " |      test_size (float, optional, between [0, 1]): Fraction of data used for test\n",
      " |      data_path (str, optional default=None): specify path to save/lookup data. Default\n",
      " |                  creates `data_download` directory and stores data there\n",
      " |      target (str, optional, default=None): Target variable\n",
      " |      seed (int, optional, default=None): Random seed to use for reproducibility\n",
      " |      \n",
      " |      inputs:\n",
      " |      -------------------------\n",
      " |      None\n",
      " |  \n",
      " |  get_data_loaders(self, target=None, transform=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from CrystalDataset:\n",
      " |  \n",
      " |  __getitem__(self, idx)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  data_augmentation(self, transform=None)\n",
      " |      Function call to deliberately augment the data\n",
      " |      \n",
      " |      input:\n",
      " |      -----------------------\n",
      " |      transformation (AbstractTransformation):\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CrystalDatasetWrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3160d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module auglichem.crystal.data._crystal_dataset:\n",
      "\n",
      "__init__(self, dataset, transform=None, split='random', batch_size=64, num_workers=0, valid_size=0.1, test_size=0.1, data_path=None, target=None, **kwargs)\n",
      "    Wrapper Class to handle splitting dataset into train, validation, and test sets\n",
      "    \n",
      "    inputs:\n",
      "    -------------------------\n",
      "    dataset (str): One of our dataset: lanthanides, perovskites, band_gap, fermi_energy,\n",
      "                                       or formation_energy\n",
      "    transform (AbstractTransformation, optional): A crystal transformation\n",
      "    split (str, default=random): Method of splitting data into train, validation, and\n",
      "                                 test\n",
      "    batch_size (int, default=64): Data batch size for train_loader\n",
      "    num_workers (int, default=0): Number of worker processes for parallel data loading\n",
      "    valid_size (float, optional, between [0, 1]): Fraction of data used for validation\n",
      "    test_size (float, optional, between [0, 1]): Fraction of data used for test\n",
      "    data_path (str, optional default=None): specify path to save/lookup data. Default\n",
      "                creates `data_download` directory and stores data there\n",
      "    target (str, optional, default=None): Target variable\n",
      "    seed (int, optional, default=None): Random seed to use for reproducibility\n",
      "    \n",
      "    inputs:\n",
      "    -------------------------\n",
      "    None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CrystalDatasetWrapper.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2887799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                               | 1/3332 [00:00<05:41,  9.77it/s]/Users/clo/miniforge3/envs/auglichem_3.8/lib/python3.8/site-packages/pymatgen/io/cif.py:1165: UserWarning: Issues encountered while parsing CIF: Some fractional co-ordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: %s\" % \"\\n\".join(self.warnings))\n",
      "100%|███████████████████████████████████████████████████████████| 3332/3332 [00:33<00:00, 100.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create transformation\n",
    "transform = [\n",
    "    SupercellTransformation()\n",
    "]\n",
    "\n",
    "# Initialize dataset object\n",
    "dataset = CrystalDatasetWrapper(\"lanthanides\", batch_size=256, valid_size=0.1, test_size=0.1)\n",
    "\n",
    "# Get train/valid/test splits as loaders\n",
    "train_loader, valid_loader, test_loader = dataset.get_data_loaders(transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b1301",
   "metadata": {},
   "source": [
    "### Initialize model with task from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f47e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "structures, _, _ = dataset[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "model = CGCNN(orig_atom_fea_len, nbr_fea_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c48a46f",
   "metadata": {},
   "source": [
    "### Initialize traning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4981f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e818fdf",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2855ac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [02:01,  4.68s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for bn, (data, target, _) in tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        input_var = (Variable(data[0]),\n",
    "                     Variable(data[1]),\n",
    "                     data[2],\n",
    "                     data[3])\n",
    "        \n",
    "        pred = model(*input_var)\n",
    "        loss = criterion(pred, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772cfea1",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01dc56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        data, target, _ = next(iter(test_loader))\n",
    "        input_var = (Variable(data[0]),\n",
    "                     Variable(data[1]),\n",
    "                     data[2],\n",
    "                     data[3])\n",
    "\n",
    "        pred = model(*input_var)\n",
    "        mae = mean_absolute_error(pred, target)   \n",
    "        \n",
    "    print(\"TEST MAE: {0:.3f}\".format(loss.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7417d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MAE: 0.168\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc37df",
   "metadata": {},
   "source": [
    "### Model saving/loading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47a4c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), \"./saved_models/example_cgcnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9152f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MAE: 0.168\n"
     ]
    }
   ],
   "source": [
    "# Instantiate new model and evaluate\n",
    "structures, _, _ = dataset[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "model = CGCNN(orig_atom_fea_len, nbr_fea_len)\n",
    "\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bd87740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MAE: 0.168\n"
     ]
    }
   ],
   "source": [
    "# Load saved model and evaluate\n",
    "model.load_state_dict(torch.load(\"./saved_models/example_cgcnn\"))\n",
    "evaluate(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
