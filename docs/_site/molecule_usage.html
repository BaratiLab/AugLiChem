<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Molecule Usage | AugLiChem</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Molecule Usage" />
<meta name="author" content="BaratiLab" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="AugLiChem supports data augmentation for organic and inorganic systems. Pre-defined augmentations, built-in data downloading, automatic data cleaning, and pre-implemented models make AugLiChem easy to use." />
<meta property="og:description" content="AugLiChem supports data augmentation for organic and inorganic systems. Pre-defined augmentations, built-in data downloading, automatic data cleaning, and pre-implemented models make AugLiChem easy to use." />
<link rel="canonical" href="http://localhost:4000/molecule_usage.html" />
<meta property="og:url" content="http://localhost:4000/molecule_usage.html" />
<meta property="og:site_name" content="AugLiChem" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Molecule Usage" />
<script type="application/ld+json">
{"url":"http://localhost:4000/molecule_usage.html","headline":"Molecule Usage","author":{"@type":"Person","name":"BaratiLab"},"description":"AugLiChem supports data augmentation for organic and inorganic systems. Pre-defined augmentations, built-in data downloading, automatic data cleaning, and pre-implemented models make AugLiChem easy to use.","@type":"WebPage","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="AugLiChem" /></head>
<body><div class="site-sidebar">

    <a class="sidebar-title" href="/">
    <img src="images/logo.png" alt="drawing" width="20"/>
	    AugLiChem

    <img src="images/Project.png" alt="drawing" width="20"/>
    </a>

    
    
    <!--  -->
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
            <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
            <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
          </svg>
        </span>
      </label>

      <form class="trigger" method="get" action="/search">
        <input type="text" name="q" placeholder="Search blog">
      </form>

      <ul id="page-list" class="trigger sidebar-list">
        
          
          
        
          
          
            <li class=""><a href="/about.html">About</a></li>
          
        
          
          
            <li class=""><a href="/crystal.html">Crystal</a></li>
          
        
          
          
            <li class=""><a href="/crystal_usage.html">Crystal Usage</a></li>
          
        
          
          
            <li class=""><a href="/molecule.html">Molecule</a></li>
          
        
          
          
            <li class="active"><a href="/molecule_usage.html">Molecule Usage</a></li>
          
        
          
          
            <li class=""><a href="/install_guide.html">Installation</a></li>
          
        
      </ul>
    <!--  -->

      
        <ul id="post-list" class="trigger sidebar-list">
          
            <li class="">
              
              <span>Oct 29, 2021</span><br>
              <a href="/2021/10/29/release.html">Release</a>
            </li>
          
        </ul>
      
    </nav>

</div>
<div class="main-wrapper"><header class="site-header" role="banner">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/">
	    AugLiChem
    </a>
  </div>
</header>
<main class="page-content" aria-label="Content">
        <div class="wrapper">
          <article class="post">

  <header class="post-header">
    <h1 class="post-title">Molecule Usage</h1>
  </header>

  <div class="post-content">
    <p>AugLiChem has been designed from the ground up with ease-of-use in mind.
Fully functional notebooks are available at our github in the <code class="language-plaintext highlighter-rouge">examples/</code> directory <a href="https://github.com/BaratiLab/AugLiChem/tree/main/examples">here</a>.
In-depth documentation of each function is given in the docstrings and can be printed out using python’s built-in <code class="language-plaintext highlighter-rouge">help()</code> function.
Using PyTorch’s CUDA support, all models and data sets can be used with GPUs.</p>

<p>This guide explains all of the features of the package.
We have also provided jupyter notebooks that are ready to run after installation.
Links to notebooks that demonstrate each type of training are provided below:</p>

<ul>
  <li>Example Notebooks:
    <ul>
      <li><a href="https://github.com/BaratiLab/AugLiChem/blob/main/examples/molecule_dataset.ipynb">Single target</a></li>
      <li><a href="https://github.com/BaratiLab/AugLiChem/blob/main/examples/molecule_multitarget_dataset.ipynb">Multitarget</a></li>
    </ul>
  </li>
</ul>

<h2 id="molecule-usage">Molecule Usage</h2>

<p>The first step is to import the relevant modules.
AugLiChem is largely self-contained, and so we import transformations, data wrapper, and models.</p>

<h3 id="setup">Setup</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">auglichem.molecule</span> <span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">RandomAtomMask</span><span class="p">,</span> <span class="n">RandomBondDelete</span><span class="p">,</span> <span class="n">MotifRemoval</span>
<span class="kn">from</span> <span class="nn">auglichem.molecule.data</span> <span class="kn">import</span> <span class="n">MoleculeDatasetWrapper</span>
<span class="kn">from</span> <span class="nn">auglichem.molecule.models</span> <span class="kn">import</span> <span class="n">AttentiveFP</span><span class="p">,</span> <span class="n">GCN</span><span class="p">,</span> <span class="n">DeepGCN</span><span class="p">,</span> <span class="n">GINE</span>
</code></pre></div></div>

<p>Next, we set up our transformations.
Transformations can be set up as a list or single transformation.
When using a list, each molecule is transformed by all transformations passed in.</p>

<h3 id="creating-augmentations">Creating Augmentations</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transforms</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">([</span>
      <span class="n">RandomAtomMask</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.3</span><span class="p">]),</span>
      <span class="n">RandomBondDelete</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]),</span>
      <span class="n">MotifRemoval</span><span class="p">(</span><span class="mf">0.6</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">RandomAtomMask</code> arguments:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">p</code> (float, list of floats, default=0.5): Probability of each atom being masked in the molecule. Masks at least one atom. If list, a value is randomly sampled uniformly between the passed in bounds for each molecule.</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">RandomBondDelete</code> arguments:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">p</code> (float, list of floats, default=0.5): Probability of each bond being deleted in the molecule. If list, a value is randomly sampled uniformly between the passed in bounds for each molecule.</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">MotifRemoval</code> arguments:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">similarity_threshold</code>: Threshold to retain motifs in augmented structure.</li>
</ul>

<p>The <code class="language-plaintext highlighter-rouge">Compose</code> object is used to apply multiple transformations at once.
It takes in transformations and applies them one at a time when called.</p>

<p><code class="language-plaintext highlighter-rouge">Compose</code> arguments:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">transforms</code> (list of transforms): A list of transforms to be applied.</li>
  <li><code class="language-plaintext highlighter-rouge">p</code> (float, optional, default=1): The probability of each transformation being applied.</li>
</ul>

<h3 id="data-loading">Data Loading</h3>
<p>After initializing our transformations, we are ready to initialize our data set.
Data sets are selected with a string, and are automatically downloaded to <code class="language-plaintext highlighter-rouge">./data_download</code> by default.
This directory is created if it is not present, and does not download the data again if it is already present.
Batch size, validation size, and test size for training and evaluation are set here.
The transforms are passed in here and scaffold splitting is supported.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">MoleculeDatasetWrapper</span><span class="p">(</span>
             <span class="n">dataset</span><span class="o">=</span><span class="s">"ClinTox"</span><span class="p">,</span>
             <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span>
             <span class="n">split</span><span class="o">=</span><span class="s">"scaffold"</span><span class="p">,</span>
             <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
             <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span>
             <span class="n">valid_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
             <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
             <span class="n">aug_time</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
             <span class="n">data_path</span><span class="o">=</span><span class="s">"./data_download"</span><span class="p">,</span>
             <span class="n">seed</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">MoleculeDatasetWrapper</code> arguments:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">dataset</code> (str): One of our dataset: lanthanides, perovskites, band_gap, fermi_energy, or formation_energy</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">transform</code> (AbstractTransformation, optional): A crystal transformation</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">split</code> (str, optional default=scaffold): random or scaffold. The splitting strategy
                                      used for train/test/validation set creation.</li>
  <li><code class="language-plaintext highlighter-rouge">split</code> (str, default=random): Method of splitting data into train, validation, and test. Ignored if doing k-fold cross validation.</li>
  <li><code class="language-plaintext highlighter-rouge">batch_size</code> (int, optional default=64): Batch size used in training</li>
  <li><code class="language-plaintext highlighter-rouge">num_workers</code> (int, optional default=0): Number of workers used in loading data</li>
  <li><code class="language-plaintext highlighter-rouge">valid_size</code> (float in [0,1], optional default=0.1):</li>
  <li><code class="language-plaintext highlighter-rouge">test_size</code> (float in [0,1],  optional default=0.1):</li>
  <li><code class="language-plaintext highlighter-rouge">aug_time</code> (int, optional default=0): Number of times to call each augmentation</li>
  <li><code class="language-plaintext highlighter-rouge">data_path</code> (str, optional default=None): specify path to save/lookup data. Default
          creates <code class="language-plaintext highlighter-rouge">data_download</code> directory and stores data there</li>
  <li><code class="language-plaintext highlighter-rouge">seed</code> (int, optional, default=None): Random seed to use for reproducibility</li>
  <li><code class="language-plaintext highlighter-rouge">cgcnn</code> (bool, optional, default=False): Set to True is using built-in CGCNN model.</li>
</ul>

<p>After loading our data, our <code class="language-plaintext highlighter-rouge">dataset</code> object has additional information from the parent class, <code class="language-plaintext highlighter-rouge">MoleculeDataset</code> that may be useful to look at.
We can look at the SMILES representation of each molecule in the data, as well as the targets:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">smiles_data</span><span class="p">)</span>
<span class="p">[</span><span class="s">'[C@@H]1([C@@H]([C@@H]([C@H]([C@@H]([C@@H]1Cl)Cl)Cl)Cl)Cl)Cl'</span>
 <span class="s">'[C@H]([C@@H]([C@@H](C(=O)[O-])O)O)([C@H](C(=O)[O-])O)O'</span>
 <span class="s">'[H]/[NH+]=C(/C1=CC(=O)/C(=C</span><span class="se">\\</span><span class="s">C=c2ccc(=C([NH3+])N)cc2)/C=C1)</span><span class="se">\\</span><span class="s">N'</span> <span class="p">...</span>
 <span class="s">'O=[Zn]'</span> <span class="s">'OCl(=O)(=O)=O'</span> <span class="s">'S=[Se]=S'</span><span class="p">]</span>
</code></pre></div></div>

<p>and the labels can be viewed with:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">labels</span><span class="p">)</span>
<span class="p">{</span><span class="s">'CT_TOX'</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">...,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="s">'FDA_APPROVED'</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">...,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])}</span>
</code></pre></div></div>

<h3 id="data-splitting">Data Splitting</h3>
<p>Using the wrapper class is preferred for easy training because of the data loader function, which creates pytorch-geometric data loaders that are easy to iterate over.
With multi-target data sets, such as ClinTox, we specify the target we want here.
If no target is selected, the first target in the downloaded data file is used.
Multiple targets can be selected for multi-target training by passing in a list of targets, or ‘all’ to use all of them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">get_data_loaders</span><span class="p">(</span><span class="s">"FDA_APPROVED"</span><span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">MoleculeDatasetWrapper.get_data_loaders()</code> argument:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">target</code> (str, list of str, optional): Target name to get data loaders for. If None,
   	                           returns the loaders for the first target. If ‘all’
                                 returns data for all targets at once, ideal for
                                 multitarget trainimg.</li>
</ul>

<p>Returns:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">train/valid/test_loader</code> (DataLoader): Data loaders containing the train, validation
                                      and test splits of our data.</li>
</ul>

<p>Now that our data is ready for training and evalutaion, we initialize our model.
Task, either regression or classification needs to be passed in.
Our dataset object stores this in the <code class="language-plaintext highlighter-rouge">task</code> attribute.</p>

<h3 id="model-initialization">Model Initialization</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AttentiveFP</span><span class="p">(</span>
            <span class="n">task</span><span class="o">=</span><span class="n">dataset</span><span class="p">.</span><span class="n">task</span><span class="p">,</span>
            <span class="n">emb_dim</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">num_timesteps</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">drop_ratio</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">AttentiveFP</code> arguments:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">task</code> (str): ‘classification’ or ‘regression’</li>
  <li><code class="language-plaintext highlighter-rouge">edge_dim</code> (int): Edge feature dimensionality.</li>
  <li><code class="language-plaintext highlighter-rouge">num_layers</code> (int): Number of GNN layers.</li>
  <li><code class="language-plaintext highlighter-rouge">num_timesteps</code> (int): Number of iterative refinement steps for global readout.</li>
  <li><code class="language-plaintext highlighter-rouge">dropout</code> (float, optional): Dropout probability. (default: :obj:<code class="language-plaintext highlighter-rouge">0.0</code>)</li>
  <li><code class="language-plaintext highlighter-rouge">output_dim</code> (int, optional): Output dimension. Defaults to 1 if task=’regression’, 2 if task=’classification’. Pass in the number of targets if doing multi-target classification.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">DeepGCN</span><span class="p">(</span>
            <span class="n">emb_dim</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
            <span class="n">aggr</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">'softmax'</span><span class="p">,</span>
            <span class="n">t</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="n">learn_t</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
            <span class="n">p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="n">learn_p</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
            <span class="n">msg_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
            <span class="n">learn_msg_scale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
            <span class="n">norm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">'batch'</span><span class="p">,</span>
            <span class="n">num_layer</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
            <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span>
<span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">DeepGCN</code> arguments:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">emb_dim</code> (int): Edge feature dimensionality.</li>
  <li><code class="language-plaintext highlighter-rouge">aggr</code> (str, optional, default=’softmax’): Aggregate function, one of ‘softmax’, ‘softmax_sg’, ‘power’, ‘add’, ‘mean’, ‘max’.</li>
  <li><code class="language-plaintext highlighter-rouge">t</code> (float optional, default=1.0): Scaling parameter for softmax and softmax_sg aggregation.</li>
  <li><code class="language-plaintext highlighter-rouge">learn_t</code> (bool optional, default=False): Flag to learn t or not.</li>
  <li><code class="language-plaintext highlighter-rouge">p</code> (float, optional, default=1.0): Power used for power aggreagation.</li>
  <li><code class="language-plaintext highlighter-rouge">learn_p</code> (bool, optional, default=False): Flag to learn p or not.</li>
  <li><code class="language-plaintext highlighter-rouge">msg_norm</code> (bool, optional, default=False): Flag to normalize messages or not.</li>
  <li><code class="language-plaintext highlighter-rouge">learn_msg_scale</code> (bool, optional, default=False): Flag to learn message norm or not.</li>
  <li><code class="language-plaintext highlighter-rouge">norm</code> (str, optional, default =’batch’): Type of norm to use in MLP. One of ‘batch’, ‘layer’, or ‘instance’.</li>
  <li><code class="language-plaintext highlighter-rouge">num_layer</code> (int, optional, default=2): Number of layers in the network.</li>
  <li><code class="language-plaintext highlighter-rouge">eps</code> (float, optional, default=1e-7): Small value to add to message output.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">GCN</span><span class="p">(</span>
            <span class="n">task</span><span class="o">=</span><span class="n">dataset</span><span class="p">.</span><span class="n">task</span><span class="p">,</span>
            <span class="n">emb_dim</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
            <span class="n">feat_dim</span><span class="o">=</span><span class="mi">256</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">pool</span><span class="o">=</span><span class="s">'mean'</span>
            <span class="n">drop_ratio</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">GCN</code> arguments:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">task</code> (str): ‘classification’ or ‘regression’</li>
  <li><code class="language-plaintext highlighter-rouge">edge_dim</code> (int): Edge feature dimensionality.</li>
  <li><code class="language-plaintext highlighter-rouge">feature_dim</code> (int): Feature dimensionality before final prediction layers.</li>
  <li><code class="language-plaintext highlighter-rouge">num_layers</code> (int): Number of GNN layers.</li>
  <li>‘pool’ (str): Pooling function to be used. One of ‘mean’, ‘add’, ‘max’.</li>
  <li><code class="language-plaintext highlighter-rouge">drop_ratio</code> (float, optional): Dropout probability. (default: :obj:<code class="language-plaintext highlighter-rouge">0.0</code>)</li>
  <li><code class="language-plaintext highlighter-rouge">output_dim</code> (int, optional): Output dimension. Defaults to 1 if task=’regression’, 2 if task=’classification’. Pass in the number of targets if doing multi-target classification.
After initializing one of the models as seen above, we are ready to train using standard PyTorch training procedure.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">GINE</span><span class="p">(</span>
            <span class="n">task</span><span class="o">=</span><span class="n">dataset</span><span class="p">.</span><span class="n">task</span><span class="p">,</span>
            <span class="n">emb_dim</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
            <span class="n">feat_dim</span><span class="o">=</span><span class="mi">256</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">pool</span><span class="o">=</span><span class="s">'mean'</span>
            <span class="n">drop_ratio</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">GINE</code> arguments:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">task</code> (str): ‘classification’ or ‘regression’</li>
  <li><code class="language-plaintext highlighter-rouge">edge_dim</code> (int): Edge feature dimensionality.</li>
  <li><code class="language-plaintext highlighter-rouge">feature_dim</code> (int): Feature dimensionality before final prediction layers.</li>
  <li><code class="language-plaintext highlighter-rouge">num_layers</code> (int): Number of GNN layers.</li>
  <li>‘pool’ (str): Pooling function to be used. One of ‘mean’, ‘add’, ‘max’.</li>
  <li><code class="language-plaintext highlighter-rouge">drop_ratio</code> (float, optional): Dropout probability. (default: :obj:<code class="language-plaintext highlighter-rouge">0.0</code>)</li>
  <li><code class="language-plaintext highlighter-rouge">output_dim</code> (int, optional): Output dimension. Defaults to 1 if task=’regression’, 2 if task=’classification’. Pass in the number of targets if doing multi-target classification.
After initializing one of the models as seen above, we are ready to train using standard PyTorch training procedure.</li>
</ul>

<h2 id="single-target-training">Single Target Training</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</code></pre></div></div>

<p>Now we have our training loop.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">bn</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)):</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="evaluation">Evaluation</h3>
<p>Evaluation requires storing all predections and labels for each batch, and so we have</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
        
   <span class="n">all_preds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Hold on to all predictions and labels
</span>        <span class="n">all_preds</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pred</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">all_labels</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>
    
    <span class="n">metric</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">pred</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">detach</span><span class="p">()[:,</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"TEST ROC: {1:.3f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">metric</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="multi-target-training">Multi-target Training</h2>

<p>AugLiChem supports multi-target training as well.
When working with a data set that has multiple targets, we can pass in a list of targets we want, or use all targets at once.
In this example, we use QM8, a multi-target regression set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">MoleculeDatasetWrapper</span><span class="p">(</span><span class="s">"QM8"</span><span class="p">,</span> <span class="n">data_path</span><span class="o">=</span><span class="s">"./data_download"</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">get_data_loaders</span><span class="p">(</span><span class="s">"all"</span><span class="p">)</span>
</code></pre></div></div>

<p>Because many of these data sets often have labels for some, but not all targets, empty label values have been filled with a placeholder that we skip during training.
Our training setup is the same as in single-target training:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</code></pre></div></div>

<p>In our training loop, we see that we only compute the loss when we have a label corresponding to a molecule.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">bn</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)):</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.</span>
        
        <span class="c1"># Get prediction for all data
</span>        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">target</span><span class="p">):</span>
            <span class="c1"># Get indices where target has a value
</span>            <span class="n">good_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">[:,</span><span class="n">idx</span><span class="p">]</span><span class="o">!=-</span><span class="mi">999999999</span><span class="p">)</span>
            
            <span class="n">current_preds</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[:,</span><span class="n">idx</span><span class="p">][</span><span class="n">good_idx</span><span class="p">]</span>
            <span class="n">current_labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">[:,</span><span class="n">idx</span><span class="p">][</span><span class="n">good_idx</span><span class="p">]</span>
            
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">current_preds</span><span class="p">,</span> <span class="n">current_labels</span><span class="p">)</span>
        
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<p>When evaluating, we need to iterate over all targets, and also skip data when there is no label</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    
    <span class="c1"># All targets we're evaluating
</span>    <span class="n">target_list</span> <span class="o">=</span> <span class="n">test_loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">target</span>
    
    <span class="c1"># Dictionaries to keep track of predictions and labels for all targets
</span>    <span class="n">all_preds</span> <span class="o">=</span> <span class="p">{</span><span class="n">target</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">target_list</span><span class="p">}</span>
    <span class="n">all_labels</span> <span class="o">=</span> <span class="p">{</span><span class="n">target</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">target_list</span><span class="p">}</span>
    
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="c1"># Get prediction for all data
</span>        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_list</span><span class="p">):</span>
            <span class="c1"># Get indices where target has a value
</span>            <span class="n">good_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">[:,</span><span class="n">idx</span><span class="p">]</span><span class="o">!=-</span><span class="mi">999999999</span><span class="p">)</span>
            
            <span class="n">current_preds</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[:,</span><span class="n">idx</span><span class="p">][</span><span class="n">good_idx</span><span class="p">]</span>
            <span class="n">current_labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">[:,</span><span class="n">idx</span><span class="p">][</span><span class="n">good_idx</span><span class="p">]</span>
            
            <span class="c1"># Save predictions and targets
</span>            <span class="n">all_preds</span><span class="p">[</span><span class="n">target</span><span class="p">].</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">current_preds</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()))</span>
            <span class="n">all_labels</span><span class="p">[</span><span class="n">target</span><span class="p">].</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">current_labels</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()))</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="p">{</span><span class="n">target</span><span class="p">:</span> <span class="bp">None</span> <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">target_list</span><span class="p">}</span>
    <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">target_list</span><span class="p">:</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">all_labels</span><span class="p">[</span><span class="n">target</span><span class="p">],</span> <span class="n">all_preds</span><span class="p">[</span><span class="n">target</span><span class="p">],</span>
                                            <span class="n">squared</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"{0} TEST RMSE: {1:.5f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">scores</span><span class="p">[</span><span class="n">target</span><span class="p">]))</span>
</code></pre></div></div>

<h2 id="training-with-cuda">Training with CUDA</h2>

<p>AugLiChem takes advantage of PyTorch’s CUDA support to leverage GPUs for faster training and evaluation.
To initialize a model on our GPU, we call the <code class="language-plaintext highlighter-rouge">.cuda()</code> function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">GCN</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="n">dataset</span><span class="p">.</span><span class="n">task</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
</code></pre></div></div>
<p>Our training setup is the same as before:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</code></pre></div></div>

<p>The only difference in our training loop is putting our data on the GPU as we train:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">bn</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)):</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
        <span class="c1"># data -&gt; GPU
</span>        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">cuda</span><span class="p">())</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<p>Which we also do for evaluation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">task</span> <span class="o">=</span> <span class="n">test_loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">task</span>
    <span class="n">set_str</span> <span class="o">=</span> <span class="s">"VALIDATION"</span> <span class="k">if</span> <span class="n">validation</span> <span class="k">else</span> <span class="s">"TEST"</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
        
        <span class="n">all_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>

            <span class="c1"># data -&gt; GPU
</span>            <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">cuda</span><span class="p">())</span>
            
            <span class="c1"># Hold on to all predictions and labels
</span>            <span class="n">all_preds</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
            <span class="n">all_labels</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>
        
        <span class="n">metric</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">pred</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">detach</span><span class="p">(),</span> <span class="n">squared</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"TEST RMSE: {0:.3f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">metric</span><span class="p">))</span>
</code></pre></div></div>

  </div>

</article>

        </div>
      </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">AugLiChem</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">BaratiLab</li><li><a class="u-email" href="mailto:your-email@domain.com">your-email@domain.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/BaratiLab"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">BaratiLab</span></a></li><li><a href="https://www.twitter.com/AmirBaratiF"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">AmirBaratiF</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>AugLiChem supports data augmentation for organic and inorganic systems. Pre-defined augmentations, built-in data downloading, automatic data cleaning, and pre-implemented models make AugLiChem easy to use.
</p>
      </div>
    </div>

  </div>

</footer>
</div>

    <script>
      (function() {

        var postList = document.getElementById('post-list');
	      var activePost = postList.getElementsByClassName('active')[0];

        var post = document.getElementsByClassName('post-content')[0];

        var headings = [];

        var tag_names = {
            h1:1,
            h2:1,
            h3:1,
            h4:1,
            h5:1,
            h6:1
        };

        function walk(root) {
            if (root.nodeType === 1 && root.nodeName !== 'script') {
                if (tag_names.hasOwnProperty(root.nodeName.toLowerCase())) {
                    headings.push(root);
                } else {
                    for (var i = 0; i < root.childNodes.length; i++) {
                        walk(root.childNodes[i]);
                    }
                }
            }
        }

        walk(post);

        if (headings.length > 0) {
          var ul = document.createElement("ul");
          ul.classList.add("sidebar-headings")
          activePost.appendChild(ul);

          for (var i=0, max=headings.length; i < max; i++) {
            var li = document.createElement("li");
            li.classList.add("sidebar-" + headings[i].tagName.toLowerCase());
            var a = document.createElement("a");
            var aText = document.createTextNode(headings[i].innerText);
            a.appendChild(aText);
            a.href = "#" + headings[i].id;
            li.appendChild(a);
            ul.appendChild(li);
          }
        }

      })();
    </script>

  </body>

</html>
